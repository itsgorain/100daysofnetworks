{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfacb0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install arxiv --upgrade --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad512df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81141bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i only use these if I want to remove annoying deprecation warnings from my analysis\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d25a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# troubleshooting: https://github.com/lukasschwab/arxiv.py/issues/43\n",
    "\n",
    "def search_arxiv(query, max_results=10):\n",
    "\n",
    "    data = {}\n",
    "    i = 0\n",
    "    \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    search = arxiv.Search(query=query, max_results=max_results)\n",
    "    \n",
    "    results = client.results(search)\n",
    "\n",
    "    #for result in search.results():\n",
    "    for result in results:\n",
    "        \n",
    "        try:\n",
    "\n",
    "            data[i] = {}\n",
    "\n",
    "            data[i]['title'] = result.title\n",
    "            data[i]['date_published'] = result.published\n",
    "            data[i]['authors'] = [a.name for a in result.authors]\n",
    "            data[i]['summary'] = result.summary\n",
    "            data[i]['url'] = result.pdf_url\n",
    "            data[i]['category'] = result.primary_category\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            print('weird arxiv error')\n",
    "        \n",
    "        # there are more fields that can be added; add as many as you need\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    df = pd.DataFrame(data).T\n",
    "    df = df[['date_published', 'title', 'authors', 'summary', 'url', 'category']]\n",
    "    df['date_published'] = pd.to_datetime(df['date_published'])\n",
    "    df.sort_values('date_published', ascending=False, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92615d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_published</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>summary</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-21 10:28:18+00:00</td>\n",
       "      <td>Multi-role Consensus through LLMs Discussions ...</td>\n",
       "      <td>[Zhenyu Mao, Jialong Li, Munan Li, Kenji Tei]</td>\n",
       "      <td>Recent advancements in large language models (...</td>\n",
       "      <td>http://arxiv.org/pdf/2403.14274v1</td>\n",
       "      <td>cs.SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-21 07:42:07+00:00</td>\n",
       "      <td>An Agnostic Biosignature Based on Modeling Pan...</td>\n",
       "      <td>[Harrison B. Smith, Lana Sinapayen]</td>\n",
       "      <td>A fundamental goal of astrobiology is to detec...</td>\n",
       "      <td>http://arxiv.org/pdf/2403.14195v1</td>\n",
       "      <td>astro-ph.EP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-19 14:26:52+00:00</td>\n",
       "      <td>On Equivalence of Likelihood-Based Confidence ...</td>\n",
       "      <td>[Peng Liu, Yili Hong, Luis A. Escobar, William...</td>\n",
       "      <td>Fatigue data arise in many research and applie...</td>\n",
       "      <td>http://arxiv.org/pdf/2403.12757v1</td>\n",
       "      <td>stat.ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-19 02:25:29+00:00</td>\n",
       "      <td>Characteristic AI Agents via Large Language Mo...</td>\n",
       "      <td>[Xi Wang, Hongliang Dai, Shen Gao, Piji Li]</td>\n",
       "      <td>The advancement of Large Language Models (LLMs...</td>\n",
       "      <td>http://arxiv.org/pdf/2403.12368v1</td>\n",
       "      <td>cs.CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-15 16:20:51+00:00</td>\n",
       "      <td>Data Ethics Emergency Drill: A Toolbox for Dis...</td>\n",
       "      <td>[Vanessa Aisyahsari Hanschke, Dylan Rees, Merv...</td>\n",
       "      <td>Researchers urge technology practitioners such...</td>\n",
       "      <td>http://arxiv.org/pdf/2403.10438v1</td>\n",
       "      <td>cs.HC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_published  \\\n",
       "0 2024-03-21 10:28:18+00:00   \n",
       "1 2024-03-21 07:42:07+00:00   \n",
       "2 2024-03-19 14:26:52+00:00   \n",
       "3 2024-03-19 02:25:29+00:00   \n",
       "4 2024-03-15 16:20:51+00:00   \n",
       "\n",
       "                                               title  \\\n",
       "0  Multi-role Consensus through LLMs Discussions ...   \n",
       "1  An Agnostic Biosignature Based on Modeling Pan...   \n",
       "2  On Equivalence of Likelihood-Based Confidence ...   \n",
       "3  Characteristic AI Agents via Large Language Mo...   \n",
       "4  Data Ethics Emergency Drill: A Toolbox for Dis...   \n",
       "\n",
       "                                             authors  \\\n",
       "0      [Zhenyu Mao, Jialong Li, Munan Li, Kenji Tei]   \n",
       "1                [Harrison B. Smith, Lana Sinapayen]   \n",
       "2  [Peng Liu, Yili Hong, Luis A. Escobar, William...   \n",
       "3        [Xi Wang, Hongliang Dai, Shen Gao, Piji Li]   \n",
       "4  [Vanessa Aisyahsari Hanschke, Dylan Rees, Merv...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Recent advancements in large language models (...   \n",
       "1  A fundamental goal of astrobiology is to detec...   \n",
       "2  Fatigue data arise in many research and applie...   \n",
       "3  The advancement of Large Language Models (LLMs...   \n",
       "4  Researchers urge technology practitioners such...   \n",
       "\n",
       "                                 url     category  \n",
       "0  http://arxiv.org/pdf/2403.14274v1        cs.SE  \n",
       "1  http://arxiv.org/pdf/2403.14195v1  astro-ph.EP  \n",
       "2  http://arxiv.org/pdf/2403.12757v1      stat.ME  \n",
       "3  http://arxiv.org/pdf/2403.12368v1        cs.CL  \n",
       "4  http://arxiv.org/pdf/2403.10438v1        cs.HC  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sometimes, it'll hit a weird error and crash; supposedly, that is on arxiv's end, not the python library used\n",
    "# just reduce max_results. 100 goes very fast, 1000 goes slower, 10000 takes a few minutes, more than that is luck\n",
    "\n",
    "query = 'artificial life'\n",
    "\n",
    "max_results = 2000\n",
    "    \n",
    "df = search_arxiv(query, max_results) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26b9e534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46b3d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'data/arxiv_artificial_life.csv'\n",
    "\n",
    "df.to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a58e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# occasionally randomly crashes; need to find a fix; maybe others can help"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
