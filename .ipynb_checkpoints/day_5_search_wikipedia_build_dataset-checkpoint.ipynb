{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ead6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia as w\n",
    "import pandas as pd\n",
    "\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535de1fa",
   "metadata": {},
   "source": [
    "# Wikipedia Edgelist Generator\n",
    "\n",
    "Feel free to use this Wikipedia edgelist generator for your own research uses. However, please keep a few things in mind.\n",
    "- For the function 'create_edgelist_df', the default iterations has been set to 2, and I did 4 for this example. The higher the number, the more you will query the Wikipedia API. Even at 4, we ended up with a network of 9,000+ nodes, so don't go overboard. Use this responsibly. Start at 2, check the results, if you need more increase to 3, check results, etc.\n",
    "- No matter what, do include a sleep() command. I have it set to 0.3 seconds between each search. A higher number will be better but take longer.\n",
    "- Always crawl responsibly. If you are too aggressive, your IP will be blocked by Wikipedia and you will get nothing.\n",
    "- Check the day_5_analysis notebook to see how the data can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90556706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wiki(search_list):\n",
    "\n",
    "    origin_pages = []\n",
    "    found_pages = []\n",
    "\n",
    "    # later, we will drop these to keep the properly named page in the network\n",
    "\n",
    "    for search in search_list:\n",
    "\n",
    "        print('searching topic: {}'.format(search))\n",
    "        \n",
    "        try:\n",
    "            #page = w.page(search)\n",
    "            #search_results = page.links\n",
    "            search_results = w.search(search)\n",
    "\n",
    "            for found_page in search_results:\n",
    "\n",
    "                origin_pages.append(search)\n",
    "                found_pages.append(found_page)\n",
    "\n",
    "        except:\n",
    "            \n",
    "            print('not found')\n",
    "            \n",
    "        sleep(0.3)\n",
    "        \n",
    "    return origin_pages, found_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47547c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edgelist_df(seed_searches, iterations=2):\n",
    "\n",
    "    completed = []\n",
    "    sources = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        print('starting iteration: {}'.format(i))\n",
    "        print()\n",
    "\n",
    "        if i == 0:\n",
    "\n",
    "            search_list = seed_searches\n",
    "\n",
    "        origin_pages, found_pages = search_wiki(search_list)\n",
    "\n",
    "        completed.extend(origin_pages)\n",
    "        sources.extend(origin_pages)\n",
    "        targets.extend(found_pages)\n",
    "\n",
    "        search_list = sorted(set([t for t in targets if t not in completed]))\n",
    "        print(len(search_list))\n",
    "        print()\n",
    "        print(search_list)\n",
    "        print()\n",
    "        \n",
    "    df = pd.DataFrame(list(zip(sources, targets)))\n",
    "    df.columns = ['source', 'target']\n",
    "                  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_searches = ['ALF (TV series)']\n",
    "\n",
    "df = create_edgelist_df(seed_searches, iterations=6) # keep it low (1-3) or this will take forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1dfeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e5288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478fad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'data/alf_edgelist.csv'\n",
    "\n",
    "df.to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the outfile looks good\n",
    "\n",
    "df = pd.read_csv(outfile)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7570a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e50ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
