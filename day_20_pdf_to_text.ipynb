{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de7ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypdf2.readthedocs.io/en/stable/user/extract-text.html\n",
    "# https://github.com/tqdm/tqdm\n",
    "\n",
    "import PyPDF2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff91e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file):\n",
    "    \n",
    "    data = \"\"\n",
    "    \n",
    "    pdf_file = open(file, 'rb')\n",
    "    pdf = PyPDF2.PdfReader(pdf_file)\n",
    "    \n",
    "    pages = len(pdf.pages)\n",
    "\n",
    "    for i in tqdm(range(pages)):\n",
    "\n",
    "        page = pdf.pages[i]\n",
    "        data = data + page.extract_text() + \" \"\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3417e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  7.72it/s]\n"
     ]
    }
   ],
   "source": [
    "file = 'data/pdf/organized_complexity.pdf'\n",
    "\n",
    "\n",
    "data = get_data(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b468612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organized Complexity: \n",
      "Is Big History a Big Computatonn\n",
      "Jean-Paul Delahaye\n",
      "Centre de Recherche en Informatique, Signal et\n",
      "Automatique, UMR CNRS 9189\n",
      "Université de Lille 1, \n",
      "jean-paul.delahaye@univ-lille1.fr  Clément Vidal\n",
      "Center Leo Apostel &\n",
      "Evolution Complexity and Cognition,\n",
      "Vrije Universiteit Brussel,\n",
      "contact@clemvidal.com\n",
      "Abstract: The concept of \"logical depth\" introduced by Charles H. Bennett (1988) seems to capture, at\n",
      "least partially, the notion of organized complexity, so central in big history. More precisely, the increase in\n",
      "organized complexity refers here to the wealth, variety and intricacy of structures, and should not be\n",
      "confused with the increase of random complexity, formalized by Kolmogorov (1965). If Bennett is right in\n",
      "proposing to assimilate organized complexity with \"computational content\", then the fundamental cause of\n",
      "the increase of complexity in the universe is the existence of computing mechanisms with memory, and\n",
      "able to cumulatively create and preserve computational contents. In this view, the universe computes,\n",
      "remembers its calculations, and reuses them to conduct further computations. Evolutionary mechanisms are\n",
      "such forms of cumulative computation with memory and we owe them the organized complexity of life.\n",
      "Language,  writing, culture, science and technology can also be analyzed as computation mechanisms\n",
      "generating, preserving and accelerating the increase in organized  complexity. The main unifying theme for\n",
      "big history is the energy rate density, a metric based on thermodynamics. However useful, this metric does\n",
      "not provide much insight into the role that information and computation play in our universe. The concept\n",
      "of “logical depth” provides a new lens to examine the increase of organized complexity. We argue in this\n",
      "paper that organized complexity is a valid and useful way to make sense of big history. Additionally,\n",
      "logical depth has a rigorous formal definition in theoretical  computer science  that hints at a broader\n",
      "research program to quantify complexity in the universe.\n",
      "Keywords: organized complexity, Kolmogorov complexity, logical depth, big history, cosmic evolution,\n",
      "evolution, complexity, complexification, computation, artificial life, philosophy of information\n",
      "American  Philosophical  Association  Newsletter  on  Philosophy  and  Computers  17 (2):  49–54.\n",
      "http://arxiv.org/abs/1609.07111  \n",
      "1Introducton\n",
      "The core concept of big history is the increase of complexity  (Christian 2004).\n",
      "Currently, it is mainly explained and analyzed within a thermodynamic framework, with\n",
      "the concept of energy rate density (Chaisson 2001; 2011) . \n",
      "However,  even  if  energy  is  universal,  it  doesn’t  capture  informational  and\n",
      "computational  dynamics,  central  in  biology,  language,  writing,  culture,  science  and\n",
      "technology. Energy is, by definition, not an informational concept. Energy can produce\n",
      "poor  or  rich  interactions;  it  can  be  wasted  or  used  with  care.  The  production  of\n",
      "computation by unit of energy varies sharply, from device to device. For example, a\n",
      "compact disc player produces much less computation per unit of energy than a regular\n",
      "1 laptop. Furthermore, Moore's law shows that from computer to computer, the energy use\n",
      "per computation decreases quickly with each new generation of microprocessor.\n",
      "Since the emergence of life, living systems have evolved memory mechanisms\n",
      "(RNA,  DNA,  neurons,  culture,  technologies)  storing  information  about  complex\n",
      "structures.  In that  way, evolution  needs  not to  start from  scratch, but  can build  on\n",
      "previously memorized structures.  Evolution is thus a cumulative process based on useful\n",
      "information, not on energy, in the sense that energy is necessary, but not sufficient.\n",
      "Informational and computational metrics are needed to measure and understand such\n",
      "mechanisms. \n",
      "We take a computational view on nature, in the tradition of digital philosophy\n",
      "(e.g.  Zuse  1970;  Chaitin  2006;  Lloyd  2005;  Wolfram  2002;  Floridi  2003) .  In  this\n",
      "framework, cosmic evolution is essentially driven by memory mechanisms that store\n",
      "previous computational contents, on which further complexity can be built. \n",
      "We first give a short history of information theories, starting with Shannon, but\n",
      "focusing on algorithmic information theory, which goes much further. We then elaborate\n",
      "on the distinction between random complexity , formalized by Kolmogorov (1965), and\n",
      "organized complexity , formalized by Bennett  (1988). Kolmogorov complexity (K) is a\n",
      "way to measure random complexity , or the informational content  of a string. It is defined\n",
      "as the size of the shortest program producing such a string. \n",
      "This tool has given rise to many applications, such as automatic classification in\n",
      "linguistics  (Cilibrasi  and  Vitanyi  2005;  Li  et  al.  2004) ,  automatic  generation  of\n",
      "phylogenetic trees (Varré, Delahaye, and Rivals 1999) , or to detect spam (Belabbes and\n",
      "Richard 2008). \n",
      "Bennett’s  logical  depth  does  not  measure  an  informational  content,  but  a\n",
      "computational content . It measures the time needed to compute a certain string S from a\n",
      "short program. A short program is considered as a more probable origin of S than a long\n",
      "program. Because of this central inclusion of time, a high (or deep) value in logical depth\n",
      "means that the object has had a rich causal history. In this sense, it can be seen as a\n",
      "mathematical and computational formalization of the concept of history. More broadly\n",
      "construed (i.e. not within the strict formal definition), we want to show that modern\n",
      "informational,  computational  and  algorithmic  theories  can  be  used  as  a  conceptual\n",
      "toolbox to analyze, understand and explore the rise of complexity in big history.\n",
      "We outline a research program based on the idea that what reflects the increase of\n",
      "complexity  in  cosmic  evolution  is  the  computational  content,  that  we  propose  to\n",
      "assimilate  with logical  depth,  i.e.  the  associated  mathematical  concept  proposed  by\n",
      "Bennett.  We  discuss  this  idea  at  different  levels,  formally,  quasi-physically  and\n",
      "philosophically. We end the paper with a discussion of issues related to this research\n",
      "program.\n",
      "2 2A very short history of informaton theories\n",
      "2.1Shannon informaton theory\n",
      "The  Shannon  entropy  (Shannon  1948) of  a  sequence  S  of  n characters  is  a\n",
      "measure of the information content of S when we suppose that every character C has a\n",
      "fixed probability pr(C) to be in position i (the same for every position). That is:\n",
      "If we know only this probabilistic information about S, it is not possible to compress the\n",
      "sequence S in another sequence of bits of length less then H(S). Actual compression\n",
      "algorithms applied to texts do search and use many other regularities beyond the relative\n",
      "frequency of letters. This is why Shannon entropy does not give the real minimal length\n",
      "in bits of a possible compressed version of S. This minimal length is given by the\n",
      "Kolmogorov complexity of S that we will now introduce. \n",
      "2.2Algorithmic informaton theory \n",
      "Since 1965, we’ve seen a renewal of informational and computational concepts,\n",
      "well  beyond  Shannon’s  information  theory.  Ray  Solomonoff,  Andreï  Kolmogorov\n",
      "(1965), Leonid Levin, Pier Martin-Löf (1966), Gregory Chaitin, Charles Bennett are the\n",
      "first contributors of this new science  (see Li and Vitányi 2008 for details) , which is\n",
      "based on the mathematical theory of computability born with Alan Turing in the 1930s.\n",
      "The Kolmogorov complexity K(S) of a string S is the length of the smallest\n",
      "program S* written in binary code and for a universal computer that produces S. This is\n",
      "the absolute informational content or incompressible information content of S, or the\n",
      "algorithmic entropy of S.\n",
      "Kolmogorov complexity is also called interchangeably  informational content  or\n",
      "incompressible  informational  content  or  algorithmic  entropy  or  Kolmogorov-Chaitin\n",
      "algorithmic complexity  or program-size complexity . \n",
      "The  invariance  theorem  states  that  K(S) does  not  really  depend on the  used\n",
      "programming  language,  provided  the  language  is  universal  (capable  to  define  every\n",
      "computable function).\n",
      "The  Kolmogorov  complexity  is  maximal  for  random  sequences:  a  random\n",
      "sequence  cannot  be  compressed.  This  is  why  K(S)  is  sometimes  called  random\n",
      "complexity of S.\n",
      "2.3Logical depth - Computatonal content \n",
      "Kolmogorov complexity is an interesting and useful concept, but it is an error to\n",
      "believe that it measures the value of the information contained in S. Not all information is\n",
      "useful:  for example,  the  information  in  a sequence  of heads  and tails  generated  by\n",
      "throwing a coin is totally useless. Indeed, if a program needs to use a random string,\n",
      "another random string would also do the job, which means that the particular random\n",
      "string chosen is not important. Kolmogorov complexity is a useful notion for defining the\n",
      "3 absolute notion of a random sequence  (Martin-Löf 1966) , but it is not capturing the\n",
      "notion of organized complexity. \n",
      "Charles H. Bennett has introduced another notion, the \"logical depth of S\". It tries\n",
      "to  measure the  real  value  of the information  contained  in  S, or as  he proposed its\n",
      "\"computational content\" (to be opposed to its 'informational content\"). A first attempt to\n",
      "formulate Bennett’s idea is to say that the logical depth of S, LD(S) is the time it takes for\n",
      "the shortest program of S, S*, to produce S. A more detailed study and discussion about\n",
      "the formulation can be found in (Bennett 1988).\n",
      "Various arguments  have been formulated  that make plausible that indeed the\n",
      "logical depth of Bennett, LD(S), is a measure of the computational content of S, or of the\n",
      "quantity of non trivial structures in S. To contrast it to \"random complexity\", we say that\n",
      "it is a measure of \"organized complexity\". \n",
      "An important property of LD(S) is the slow growth’s law (see Bennett 1988) : an\n",
      "evolutionary system S( t) cannot have its logical depth LD(S( t)) that grows suddenly. \n",
      "This property (which is not true for the Kolmogorov complexity) seems to correspond to\n",
      "the intuitive idea that in an evolutionary process, whether it is biological, cultural or\n",
      "technological, the creation of new innovative structures cannot be quick.\n",
      "Variants of logical depth have been explored (Lathrop and Lutz 1999; Antunes et\n",
      "al. 2006; Doty and Moser 2007) , as well as other similar ideas, such as  sophistication\n",
      "(Koppel 1987; 1995; Koppel and Atlan 1991; Antunes and Fortnow 2003) ,  facticity\n",
      "(Adriaans  2009;  2012)  or  effective  complexity  (Gell-Mann  and  Lloyd  1996;  2004) .\n",
      "Studies have established properties of these measures, and have discussed them (Antunes,\n",
      "Souto, and Teixeira 2012; Bloem, Rooij, and Adriaans 2015) . Importantly, results show\n",
      "that these various notions are closely related (Ay, Muller, and Szkola 2010; Antunes et al.\n",
      "2016). In this paper we focus on logical depth, whose definition is general, simple and\n",
      "easy to understand.\n",
      "3Outline of a research program\n",
      "3.1Three levels of analysis\n",
      "Let us first distinguish three conceptual levels of the notion of computational\n",
      "content: mathematical, quasi-physical and philosophical. \n",
      "First, we presented the notion of computational content as the logical depth, as\n",
      "defined by Bennett. Other formal definitions of computational content may be possible,\n",
      "but this one has proven to be robust. This definition has been applied to derive  a method\n",
      "to classify and characterize the complexity of various kinds of images (Zenil, Delahaye,\n",
      "and Gaucherel 2012) . More applications promise to be successful, in the same way as\n",
      "Kolmogorov complexity proved useful. \n",
      "Second,  we  have  the  quasi-physical  level,  linking  computation  theory  with\n",
      "physics (Bennett 2012; Feynman 1998) . This has not yet been developed in a satisfactory\n",
      "manner.  Maybe  this  would  require  physics  to  consider  a  fundamental  notion  of\n",
      "computation, in the same way as it integrated the notion of information (used for example\n",
      "in thermodynamics). The transfer of purely mathematical or computer science concepts\n",
      "4 into  physics  is  a  delicate  step.  Issues  relate  for  example  to  the  thermodynamics  of\n",
      "computation,  the  granularity  of computation  we  look  at,  or the  design  of  hardware\n",
      "architectures actually possible physically. \n",
      "The concept of thermodynamic depth introduced by Seth Lloyd et Heinz Pagels\n",
      "(1988) is defined as \"the amount of entropy produced during a state's actual evolution\". It\n",
      "is a first attempt to translate Bennett’s idea in a more physical context. However the\n",
      "definition is rather imprecise and it seems not really possible to use it in practice. It is not\n",
      "even clear that it reflects really the most important features of the mathematical concept,\n",
      "since \"thermodynamical depth can be very system dependant: some systems arrive at a\n",
      "very trivial state through much dissipation; others at very non trivial states with little\n",
      "dissipation\" (Bennett 1990, 142) .\n",
      "Third, the philosophical level brings the bigger picture. It captures the idea that\n",
      "building complexity takes time and interactions (computation time). Objects measured\n",
      "with a deep computational content necessarily have a rich causal history. It thus reflects a\n",
      "kind of historical complexity. Researchers in various fields have already recognized its\n",
      "use  (Gell-Mann 1994; Danchin 2003; Mitchell 2009; Mayfield 2013; Steinhart 2014;\n",
      "Dessalles, Gaucherel, and Gouyon 2016) .\n",
      "This philosophical level may also hint at a theory of value based on computational\n",
      "content (Steinhart 2014, chap. 73; Delahaye and Vidal 2018) . For example, a library has a\n",
      "huge computational content, because it is the result of many brains who worked to write\n",
      "books. Burning a library can thus be said to be unethical. \n",
      "3.2Computer simulatons\n",
      "A major development of modern science is the use of computer simulations.\n",
      "Simulations are essential tools to explore dynamical and complex interactions that cannot\n",
      "be explored with simple equations. Since the most important and interesting scientific\n",
      "issues are complex, simulations will likely be used more and more systematically in\n",
      "science (Vidal 2008).\n",
      "The difficulty with simulations is often to interpret the results. We propose that\n",
      "Kolmogorov complexity (K) and logical depth (LD) would be valuable tools to test\n",
      "various hypotheses relative to the growth of complexity. Approximations of K and LD\n",
      "have  already  been  applied  to  classify  the  complexity  of  animal  behavior.  These\n",
      "algorithmic methods do validate experimental results obtained with traditional cognitive-\n",
      "behavioural methods (Zenil, Marshall, and Tegnér 2015) .  \n",
      "For an application of K-complexity and LD to an artificial life simulation, see for\n",
      "example  the  work  of  Gaucherel  (2014),  comparing  a  Lamarkian  algorithm  with  a\n",
      "Darwinian algorithm in an artificial life simulation. Gaucherel proposes the following\n",
      "three-step methodology:\n",
      "(1) identification of the shortest program able to numerically model the studied system\n",
      "(also called the Kolmogorov–Solomonoff complexity); (2) running the program, once if\n",
      "there are no stochastic components in the system, several times if stochastic components\n",
      "are there; and (3) computing the time needed to generate the system with LD  complexity.\n",
      "5 More  generally,  in  the  domain  of  Artificial  Life,  it  is  fundamental  to  have  metric\n",
      "monitoring if the complexity of the simulated environment really increases. Testing the\n",
      "logical depth of entities in virtual environments would prove very useful.\n",
      "3.3Emergy and logical depth\n",
      "In  systems  ecology,  an  energetic  counterpart  to  the  notion  of  computational\n",
      "content has been proposed. It is called emergy (with an “m”) and is defined as the value\n",
      "of a system, be it living, social or technological, as measured by the solar energy that was\n",
      "used to make it (e.g. Odum 2007).  This is very similar to the logical depth, defined by\n",
      "the quantity of computation that needs to be performed to make a structured object. \n",
      "Does this mean that energetic content (emergy) and computational content are one\n",
      "and the same thing? No, and one argument amongst many others is that the energetic\n",
      "content  to produce a computation  diminishes  tremendously  with new generations  of\n",
      "computers (c.f.  Moore’s law). \n",
      "4Discussion\n",
      "We formulate here a few questions that the reader may have, and propose some answers.\n",
      "Before the emergence of life, does cosmic evolution produces any computational\n",
      "content?\n",
      "Yes,  but  the  memorization  of  calculus  is  non-existent  or  very  limited.  A\n",
      "computation does not necessarily mean a computation with memorization. For example,\n",
      "atoms such as H or molecules such as H 2O are all the same, there is no memory of what\n",
      "has happened to a particular atom or molecule. What lacks in these cases is computation\n",
      "with a memory mechanism. \n",
      "The increase of complexity accelerates with the emergence of more and more\n",
      "sophisticated and reliable memory mechanisms. In this computational view, the main\n",
      "cosmic  evolution  threshold  is  the  emergence  of  life,  because  it  creates  a  memory\n",
      "mechanism  in  the  universe  (RNA/DNA).  From  a  cosmic  perspective,  complexity\n",
      "transitions  have decelerated  from the Big Bang to the origin of life,  and started to\n",
      "accelerate since life appeared (Aunger 2007). The emergence of life thus constitutes the\n",
      "tipping point in the dynamics of complexity transitions.\n",
      "Furthermore, evolutionary transitions are marked with progress in the machinery\n",
      "to manipulate information, particularly regarding the  memorization of information. For\n",
      "example, we can think of RNA/DNA, nervous systems, language, writing, and computers\n",
      "as successive revolutions in information processing (Dawkins 1995).\n",
      "6 Why would evolution care about minimal-sized programs?\n",
      "We care about short programs, not necessarily minimally-sized programs proven\n",
      "to be so. The shortest program (or a near shortest program) producing S is the most\n",
      "probable origin for S. Let us illustrate this point with a short story. Imagine that you walk\n",
      "in the forest, and find engraved on a tree trunk 1,000,000 digits of π, written in binary\n",
      "code. What is the most probable explanation of this phenomenon? There are 2  1  000  000\n",
      "strings of the same size, so the chance explanation has to be excluded. The first plausible\n",
      "explanation is rather that it is a hoax. Somebody computed digits of π, and engraved them\n",
      "here. If a human did not do it, a physical mechanism may have done it, that we can\n",
      "equate with a short program producing π. The likely origin of the digits of π is a short\n",
      "program producing them, not a long program of the kind print(S), which would have a\n",
      "length of about one million.  \n",
      "Another  example  from  the  history  of  science  is  the  now  refuted  idea  of\n",
      "spontaneous generation (Strick 2000). From our computational perspective, it would be\n",
      "extremely improbable that sophisticated and complex living systems would appear in a\n",
      "few days. The slow growth law says that they necessarily needed time to appear.\n",
      "Couldn’t you have a short program computing for a long time, with a trivial output,\n",
      "which would mean that a trivial structure would have a deep logical depth? \n",
      "Of course, programs computing a long time and producing a trivial output are\n",
      "easy to write. For example, it is easy to write a short program, computing for a long time,\n",
      "and producing a sequence of 1000 zeros. This long computation wouldn’t give the logical\n",
      "depth the string, because there also a shorter program computing much more rapidly and\n",
      "producing these 1000 zeros. This means that objects with a deep logical depth can’t be\n",
      "trivial. \n",
      "Why focus on decompression times and not compression times? \n",
      "The compression time is the time necessary to resolve a problem: knowing S, find\n",
      "the shortest (or a near shortest) program producing S. \n",
      "By  contrast,  the  decompression  time  is  the  time  necessary  to  produce  the\n",
      "sequence S from a near shortest program that produces S. It is thus a very different\n",
      "problem from compression.\n",
      "If we imagine that the world contains many explicit or implicit programs —and\n",
      "we certainly can think our world as a big set of programs producing objects— then the\n",
      "probability of an encounter with a sequence S depends only on the time necessary for a\n",
      "short program to produce S (at first glance, only short program exist).\n",
      "7 Complexity should be defined dynamically, not statically.\n",
      "A measure is by definition something static, at one point in time. However, we\n",
      "can compare two points in time, and thus study the relative LD, and the dynamics of\n",
      "organized complexity.\n",
      "Let us take a concrete example. What is the difference in LD-complexity between\n",
      "a living and a dead body? At the time of death, the computational content would be\n",
      "almost the same for both. This is because the computational content measures the causal\n",
      "history. A dead person still has had a complex history. Other metrics may be used to\n",
      "capture more dynamical aspects such as informational flows or energy flows. \n",
      "5Conclusion\n",
      "To sum up, we want to emphasize again that random complexity and organized\n",
      "complexity are two distinct concepts. Both have strong theoretical foundations, and have\n",
      "been applied to measure the complexity of particular strings. More generally, they can be\n",
      "applied in practice to assess the complexity of some computer simulations. In principle,\n",
      "they may thus be applied to any physical object, given that it is modelled digitally or in a\n",
      "computer simulation.\n",
      "         Applied  to  big  history,  organized  complexity  suggests  that  evolution  retains\n",
      "computational contents via memory mechanisms, whether they are biological, cultural or\n",
      "technological. Organized complexity further indicates that major evolutionary transitions\n",
      "are  linked  with  the  emergence  of  new  mechanisms  that  compute  and  memorize.  \n",
      "            Somewhat ironically, complexity measures in big history have neglected history.\n",
      "We have argued that the computational content, reflecting the causal history of an object\n",
      "and formalized as logical depth − as defined by Bennett − is a promising complexity\n",
      "metric in addition to existing energetic metrics. It may well become a general measure of\n",
      "complexity.\n",
      "6References\n",
      "Adriaans, Pieter. 2009. “Between Order and Chaos: The Quest for Meaningful Information.”  Theory of\n",
      "Computing Systems 45 (4): 650–74. doi:10.1007/s00224-009-9173-y.\n",
      "———. 2012. “Facticity as the Amount of Self-Descriptive Information in a Data Set.” ArXiv:1203.2245\n",
      "[Cs, Math], March. http://arxiv.org/abs/1203.2245.\n",
      "Antunes, Luís, Bruno Bauwens, André Souto, and Andreia Teixeira. 2016. “Sophistication vs Logical\n",
      "Depth.” Theory of Computing Systems , March, 1–19. doi:10.1007/s00224-016-9672-6.\n",
      "Antunes,  Luís,  and  Lance  Fortnow.  2003.  “Sophistication  Revisited.”  In  Automata,  Languages  and\n",
      "Programming, edited by Jos C. M. Baeten, Jan Karel Lenstra, Joachim Parrow, and Gerhard J.\n",
      "Woeginger,  267–77.  Lecture  Notes  in  Computer  Science  2719.  Springer  Berlin  Heidelberg.\n",
      "doi:10.1007/3-540-45061-0_23.\n",
      "Antunes, Luís, Lance Fortnow, Dieter van Melkebeek, and N. V. Vinodchandran. 2006. “Computational\n",
      "Depth: Concept and Applications.”  Theoretical Computer Science , Foundations of Computation\n",
      "Theory (FCT 2003), 354 (3): 391–404. doi:10.1016/j.tcs.2005.11.033.\n",
      "8 Antunes, Luís, Andre Souto, and Andreia Teixeira. 2012. “Robustness of Logical Depth.” In  How the\n",
      "World Computes, edited by S. Barry Cooper, Anuj Dawar, and Benedikt Löwe, 29–34. Lecture\n",
      "Notes in Computer Science 7318. Springer Berlin Heidelberg. doi:10.1007/978-3-642-30870-3_4.\n",
      "Aunger, Robert. 2007. “Major Transitions in ‘big’ History.” Technological Forecasting and Social Change\n",
      "74 (8): 1137–63. doi:10.1016/j.techfore.2007.01.006.\n",
      "Ay, N., M. Muller, and A. Szkola. 2010. “Effective Complexity and Its Relation to Logical Depth.” IEEE\n",
      "Transactions  on  Information  Theory  56  (9):  4593–4607.  doi:10.1109/TIT.2010.2053892.\n",
      "http://arxiv.org/abs/0810.5663.\n",
      "Belabbes, Sihem, and Gilles Richard. 2008. “Spam Filtering without Text Analysis.” In Global E-Security,\n",
      "edited  by  Hamid  Jahankhani,  Kenneth  Revett,  and  Dominic  Palmer-Brown,  144–52.\n",
      "Communications  in  Computer  and  Information  Science  12.  Springer  Berlin  Heidelberg.\n",
      "doi:10.1007/978-3-540-69403-8_18.\n",
      "Bennett, C.H. 1988. “Logical Depth and Physical Complexity.” In The Universal Turing Machine: A Half-\n",
      "Century  Survey,  edited  by  R.  Herken,  227–257.  Oxford  University  Press.\n",
      "http://researcher.watson.ibm.com/researcher/files/us-bennetc/UTMX.pdf.\n",
      "———. 1990. “How to Define Complexity in Physics and Why.” In Complexity, Entropy, and the Physics\n",
      "of Information, edited by Wojciech H. Zurek, 137–48. Santa Fe Institute Studies in the Sciences of\n",
      "Complexity, v. 8. Redwood City, Calif: Addison-Wesley Pub. Co.\n",
      "———. 2012. “What Increases When a Self-Organizing System Organizes Itself? Logical Depth to the\n",
      "Rescue.” The Quantum Pontiff. http://dabacon.org/pontiff/?p=5912.\n",
      "Bloem,  Peter,  Steven  de  Rooij,  and  Pieter  Adriaans.  2015.  “Two  Problems  for  Sophistication.”  In\n",
      "Algorithmic Learning Theory , edited by Kamalika Chaudhuri, Claudio Gentile, and Sandra Zilles,\n",
      "379–94.  Lecture  Notes  in  Computer  Science  9355.  Springer  International  Publishing.\n",
      "doi:10.1007/978-3-319-24486-0_25.\n",
      "Chaisson, E. J. 2001. Cosmic Evolution: The Rise of Complexity in Nature . Harvard University Press.\n",
      "———. 2011. “Energy Rate Density as a Complexity Metric and Evolutionary Driver.” Complexity 16 (3):\n",
      "27–40.  doi:10.1002/cplx.20323.\n",
      "http://www.tufts.edu/as/wright_center/eric/reprints/EnergyRateDensity_I_FINAL_2011.pdf.\n",
      "Chaitin, G. J. 2006. Meta Math! Atlantic Books.\n",
      "Christian, D. 2004. Maps of Time: An Introduction to Big History . University of California Press.\n",
      "Cilibrasi, R., and P. M. B. Vitanyi. 2005. “Clustering by Compression.” IEEE Transactions on Information\n",
      "Theory 51 (4): 1523–45. doi:10.1109/TIT.2005.844059. http://arxiv.org/abs/cs/0312044.\n",
      "Danchin,  Antoine.  2003.  The  Delphic  Boat:  What  Genomes  Tell  Us .  Translated  by  Alison  Quayle.\n",
      "Cambridge, MA: Harvard University Press.\n",
      "Dawkins, Richard. 1995. River out of Eden: A Darwinian View of Life . Basic Books.\n",
      "Delahaye, J. P., and C. Vidal. 2018. “Universal Ethics: Organized Complexity as an Intrinsic Value.” In\n",
      "Evolution, Development and Complexity: Multiscale Evolutionary Models of Complex Adaptive\n",
      "Systems, edited by Georgi Yordanov Georgiev, Claudio Flores Martinez, Michael E. Price, and\n",
      "John M. Smart. Springer. doi:10.5281/zenodo.1172976. https://doi.org/10.5281/zenodo.1172976.\n",
      "Dessalles, Jean-Louis, Cédric Gaucherel, and Pierre-Henri Gouyon. 2016.  Le Fil de La Vie: La Face\n",
      "Immatérielle Du Vivant . Paris: Odile Jacob.\n",
      "Doty, David, and Philippe Moser. 2007. “Feasible Depth.” In Computation and Logic in the Real World ,\n",
      "edited by S. Barry Cooper, Benedikt Löwe, and Andrea Sorbi, 228–37. Lecture Notes in Computer\n",
      "Science 4497. Springer Berlin Heidelberg. doi:10.1007/978-3-540-73001-9_24.\n",
      "Feynman, Richard Phillips. 1998. Feynman Lectures on Computation . Edited by J. G. Hey and Robin W.\n",
      "Allen. Addison-Wesley Longman Publishing Co., Inc.\n",
      "Floridi, L., ed. 2003.  The Blackwell Guide to the Philosophy of Computing and Information . Blackwell\n",
      "Publishing.\n",
      "Gaucherel,  Cédric.  2014.  “Ecosystem  Complexity  Through  the  Lens  of  Logical  Depth:  Capturing\n",
      "Ecosystem Individuality.” Biological Theory 9 (4): 440–51. doi:10.1007/s13752-014-0162-2.\n",
      "Gell-Mann, Murray. 1994. The Quark and the Jaguar: Adventures in the Simple and the Complex . New\n",
      "York: Freeman.\n",
      "Gell-Mann,  Murray,  and  Seth  Lloyd.  1996.  “Information  Measures,  Effective  Complexity,  and  Total\n",
      "Information.”  Complexity 2 (1): 44–52. doi:10.1002/(SICI)1099-0526(199609/10)2:1<44::AID-\n",
      "CPLX10>3.0.CO;2-X.\n",
      "———. 2004. “Effective Complexity.” In Nonextensive Entropy–Interdisciplinary Applications , edited by\n",
      "Constantino Tsallis and Murray Gell-Mann, 387–98. Oxford, UK: Oxford University Press.\n",
      "9 Kolmogorov, Andrei N. 1965. “Three Approaches to the Quantitative Definition Ofinformation.” Problems\n",
      "of  Information  Transmission  1  (1):  1–7.  doi:10.1080/00207166808803030.\n",
      "http://alexander.shen.free.fr/library/Kolmogorov65_Three-Approaches-to-Information.pdf.\n",
      "Koppel,  Moshe. 1987. “Complexity, Depth,  and Sophistication.”  Complex  Systems 1 (6):  1087–1091.\n",
      "http://www.complex-systems.com/pdf/01-6-4.pdf.\n",
      "———. 1995. “Structure.” In  The Universal Turing Machine: A Half-Century Survey , edited by Rolf\n",
      "Herken, 2nd ed, 403–19. New York: Springer-Verlag.\n",
      "Koppel, Moshe, and Henri Atlan. 1991. “An Almost Machine-Independent Theory of Program-Length\n",
      "Complexity,  Sophistication,  and  Induction.”  Information  Sciences  56  (1):  23–33.\n",
      "doi:10.1016/0020-0255(91)90021-L.\n",
      "Lathrop,  James  I.,  and  Jack  H.  Lutz.  1999.  “Recursive  Computational  Depth.”  Information  and\n",
      "Computation 153 (1): 139–72.\n",
      "Li,  Ming,  Xin  Chen,  Xin  Li,  Bin  Ma,  and  P.  M.  B.  Vitanyi.  2004.  “The  Similarity  Metric.”  IEEE\n",
      "Transactions  on  Information  Theory  50  (12):  3250–64.  doi:10.1109/TIT.2004.838101.\n",
      "http://arxiv.org/abs/cs/0111054.\n",
      "Li, Ming, and P. M. B. Vitányi. 2008. An Introduction to Kolmogorov Complexity and Its Applications .\n",
      "Springer.\n",
      "Lloyd, Seth. 2005.  Programming the Universe: A Quantum Computer Scientist Takes on the Cosmos .\n",
      "Vintage Books.\n",
      "Lloyd, Seth, and Heinz Pagels. 1988. “Complexity as Thermodynamic Depth.” Annals of Physics 188 (1):\n",
      "186–213. doi:10.1016/0003-4916(88)90094-2.\n",
      "Martin-Löf, Per. 1966. “The Definition of Random Sequences.”  Information and Control  9 (6): 602–19.\n",
      "doi:10.1016/S0019-9958(66)80018-9.\n",
      "Mayfield, John. 2013. The Engine of Complexity: Evolution as Computation . Columbia University Press.\n",
      "Mitchell, Melanie. 2009. Complexity: A Guided Tour . Oxford University Press.\n",
      "Odum, Howard T. 2007. Environment, Power, and Society for the Twenty-First Century: The Hierarchy of\n",
      "Energy. New York: Columbia University Press.\n",
      "Shannon, Claude E. 1948. “A Mathematical Theory of Communication.” Bell System Technical Journal  27:\n",
      "379–423 & 623–56.\n",
      "Steinhart, Eric Charles. 2014. Your Digital Afterlives: Computational Theories of Life after Death . Palgrave\n",
      "Macmillan.\n",
      "Strick,  James  Edgar.  2000.  Sparks  of  Life:  Darwinism  and  the  Victorian  Debates  over  Spontaneous\n",
      "Generation. Cambridge, Mass: Harvard University Press.\n",
      "Varré, J. S., J. P. Delahaye, and E. Rivals. 1999. “Transformation Distances: A Family of Dissimilarity\n",
      "Measures  Based  on  Movements  of  Segments.”  Bioinformatics 15  (3):  194–202.\n",
      "doi:10.1093/bioinformatics/15.3.194. http://bioinformatics.oxfordjournals.org/content/15/3/194.\n",
      "Vidal, C. 2008. “The Future of Scientific Simulations: From Artificial Life to Artificial Cosmogenesis.” In\n",
      "Death  And  Anti-Death ,  edited  by  Charles  Tandy,  6:  Thirty  Years  After  Kurt  Gödel  (1906-\n",
      "1978).:285–318. Ria University Press. http://arxiv.org/abs/0803.1087.\n",
      "Wolfram, S. 2002. A New Kind of Science . Wolfram Media Inc., Champaign, IL.\n",
      "Zenil,  Hector,  Jean-Paul  Delahaye,  and  Cédric  Gaucherel.  2012.  “Image  Characterization  and\n",
      "Classification  by  Physical  Complexity.”  Complexity 17  (3):  26–42.  doi:10.1002/cplx.20388.\n",
      "http://arxiv.org/abs/1006.0051.\n",
      "Zenil, Hector, James A. R. Marshall, and Jesper  Tegnér. 2015. “Approximations of Algorithmic and\n",
      "Structural Complexity Validate Cognitive-Behavioural Experimental Results.” ArXiv:1509.06338\n",
      "[Cs, Math, q-Bio]. http://arxiv.org/abs/1509.06338.\n",
      "Zuse, K. 1970.  Calculating Space. Translated by MIT. Massachusetts Institute of Technology, Project\n",
      "MAC. ftp://ftp.idsia.ch/pub/juergen/zuserechnenderraum.pdf.\n",
      "10 \n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d846d0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31582"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a60d8ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'More precisely, the increase in\\norganized complexity refers here to the wealth, variety and intricacy of structures, and should not be\\nconfused with the increase of random complexity, formalized by Kolmogorov (1965).'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to show that NLP is now possible\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences = sent_tokenize(data)\n",
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4242a889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7e98a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
